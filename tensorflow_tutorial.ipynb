{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4dd490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0e200",
   "metadata": {},
   "source": [
    "First we need to set up some basic variables such as our batch size, country and data directories/paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a129f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRY = \"phl\"\n",
    "CSV_PATH = \"../../CCI/hmbaier/cci_example.csv\"\n",
    "IMAGERY_DIR = \"../../CCI/hmbaier/\"\n",
    "BATCH_SIZE = 64\n",
    "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1c265",
   "metadata": {},
   "source": [
    "Next, we create a variables called files that contains the name of every image in our base folder, then we subset it to just the iamges for our selected country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(IMAGERY_DIR)\n",
    "files = [IMAGERY_DIR + i for i in files if COUNTRY in i]\n",
    "\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c6b16",
   "metadata": {},
   "source": [
    "We will use a type of Python object called a Generator for our datalaoder. You can read more about them here: https://realpython.com/introduction-to-python-generators/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f8da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(files, split):\n",
    "\n",
    "    \"\"\" Split data into training and validation sets \"\"\"\n",
    "\n",
    "    train_num = int(len(files) * split)\n",
    "\n",
    "    train = random.sample(files, train_num)\n",
    "    val = [i for i in files if i not in train]\n",
    "\n",
    "    return train, val\n",
    "\n",
    "\n",
    "def get_train():\n",
    "\n",
    "    \"\"\" Training data generator \"\"\"\n",
    "\n",
    "    for file in train_files:\n",
    "        \n",
    "        # Grab the school_id from the image name\n",
    "        school_id = file.split(\"/\")[4].split(\"_\")[0]\n",
    "        \n",
    "        # Grab the test score for the current school from our scores dataframe\n",
    "        score = df[df[\"school_id\"] == school_id][\"y\"].squeeze()\n",
    "        \n",
    "        # Read in our image and normalize it by divding it by the maximum value (this normalization is super important!)\n",
    "        im = cv2.imread(file)\n",
    "        im = im / np.max(im)\n",
    "\n",
    "        # Create a tuple with (image array, test score) and return it\n",
    "        ret = ( np.array(im), np.reshape(np.array(score), (-1, 1)) )\n",
    "        \n",
    "        yield ret\n",
    "\n",
    "\n",
    "def get_val():\n",
    "\n",
    "    \"\"\" Validation data generator \"\"\"\n",
    "\n",
    "    for file in val_files:\n",
    "        school_id = file.split(\"/\")[4].split(\"_\")[0]\n",
    "        score = df[df[\"school_id\"] == school_id][\"y\"].squeeze()\n",
    "        im = cv2.imread(file)\n",
    "        im = im / np.max(im)\n",
    "        ret = ( np.array(im), np.reshape(np.array(score), (-1, 1)) )\n",
    "        yield ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbeef08",
   "metadata": {},
   "source": [
    "Read in our test scores dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a28236f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>school_id</th>\n",
       "      <th>test_score</th>\n",
       "      <th>scaled_score</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phl</td>\n",
       "      <td>107022</td>\n",
       "      <td>105.30</td>\n",
       "      <td>35.583573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phl</td>\n",
       "      <td>107023</td>\n",
       "      <td>137.05</td>\n",
       "      <td>58.458213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phl</td>\n",
       "      <td>107024</td>\n",
       "      <td>142.39</td>\n",
       "      <td>62.305476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phl</td>\n",
       "      <td>107025</td>\n",
       "      <td>166.03</td>\n",
       "      <td>79.337176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phl</td>\n",
       "      <td>107026</td>\n",
       "      <td>152.81</td>\n",
       "      <td>69.812680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country school_id  test_score  scaled_score  y\n",
       "0     phl    107022      105.30     35.583573  0\n",
       "1     phl    107023      137.05     58.458213  1\n",
       "2     phl    107024      142.39     62.305476  1\n",
       "3     phl    107025      166.03     79.337176  1\n",
       "4     phl    107026      152.81     69.812680  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc81c8",
   "metadata": {},
   "source": [
    "Create a TensorFlow dataloader using the ```tf.data.Dataset.from_generator``` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e67207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nCDF files:  5502\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of image files for {COUNTRY}: {str(len(files))}\")\n",
    "\n",
    "train_files, val_files = train_test_split(files, .75)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(generator = get_train, output_types = (tf.float32, tf.float32)).batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_generator(generator = get_val, output_types = (tf.float32, tf.float32)).batch(BATCH_SIZE)\n",
    "\n",
    "print(\"Number of training files: \", len(train_files))\n",
    "print(\"Number of validation files: \", len(val_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae6d022",
   "metadata": {},
   "source": [
    "Create an compile our model using our selected parameters and metrics. In this case, I am using the MeanAbsoluteError Loss and a learning rate of 0.0001 along with the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8fc0a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet.resnet56(img_input = tf.keras.layers.Input((256, 256, 3)), classes = 1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "    loss = tf.keras.losses.MeanAbsoluteError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c25e9ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq = 5 * BATCH_SIZE)\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b69747",
   "metadata": {},
   "source": [
    "And finally, train your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8626c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "65/65 [==============================] - 116s 2s/step - loss: 1.0558 - val_loss: 0.9999\n",
      "Epoch 2/25\n",
      "65/65 [==============================] - 116s 2s/step - loss: 0.9505 - val_loss: 0.9024\n",
      "Epoch 3/25\n",
      "65/65 [==============================] - 116s 2s/step - loss: 0.8599 - val_loss: 0.8187\n",
      "Epoch 4/25\n",
      "65/65 [==============================] - 117s 2s/step - loss: 0.7820 - val_loss: 0.7466\n",
      "Epoch 5/25\n",
      "59/65 [==========================>...] - ETA: 9s - loss: 0.7184 \n",
      "Epoch 00005: saving model to training/cp-0005.ckpt\n",
      "65/65 [==============================] - 119s 2s/step - loss: 0.7148 - val_loss: 0.6843\n",
      "Epoch 6/25\n",
      "65/65 [==============================] - 115s 2s/step - loss: 0.6567 - val_loss: 0.6304\n",
      "Epoch 7/25\n",
      "65/65 [==============================] - 114s 2s/step - loss: 0.6065 - val_loss: 0.5838\n",
      "Epoch 8/25\n",
      "65/65 [==============================] - 116s 2s/step - loss: 0.5629 - val_loss: 0.5433\n",
      "Epoch 9/25\n",
      "65/65 [==============================] - 117s 2s/step - loss: 0.5251 - val_loss: 0.5081\n",
      "Epoch 10/25\n",
      "54/65 [=======================>......] - ETA: 16s - loss: 0.4974\n",
      "Epoch 00010: saving model to training/cp-0010.ckpt\n",
      "65/65 [==============================] - 119s 2s/step - loss: 0.4922 - val_loss: 0.4776\n",
      "Epoch 11/25\n",
      "65/65 [==============================] - 122s 2s/step - loss: 0.4637 - val_loss: 0.4510\n",
      "Epoch 12/25\n",
      "65/65 [==============================] - 121s 2s/step - loss: 0.4388 - val_loss: 0.4278\n",
      "Epoch 13/25\n",
      "65/65 [==============================] - 120s 2s/step - loss: 0.4172 - val_loss: 0.4077\n",
      "Epoch 14/25\n",
      "65/65 [==============================] - 121s 2s/step - loss: 0.3983 - val_loss: 0.3901\n",
      "Epoch 15/25\n",
      "49/65 [=====================>........] - ETA: 24s - loss: 0.3868\n",
      "Epoch 00015: saving model to training/cp-0015.ckpt\n",
      "65/65 [==============================] - 120s 2s/step - loss: 0.3818 - val_loss: 0.3748\n",
      "Epoch 16/25\n",
      "65/65 [==============================] - 121s 2s/step - loss: 0.3675 - val_loss: 0.3614\n",
      "Epoch 17/25\n",
      "65/65 [==============================] - 120s 2s/step - loss: 0.3549 - val_loss: 0.3497\n",
      "Epoch 18/25\n",
      "65/65 [==============================] - 121s 2s/step - loss: 0.3439 - val_loss: 0.3394\n",
      "Epoch 19/25\n",
      "65/65 [==============================] - 121s 2s/step - loss: 0.3344 - val_loss: 0.3305\n",
      "Epoch 20/25\n",
      "44/65 [===================>..........] - ETA: 32s - loss: 0.3291\n",
      "Epoch 00020: saving model to training/cp-0020.ckpt\n",
      "65/65 [==============================] - 121s 2s/step - loss: 0.3260 - val_loss: 0.3226\n",
      "Epoch 21/25\n",
      "65/65 [==============================] - 120s 2s/step - loss: 0.3186 - val_loss: 0.3157\n",
      "Epoch 22/25\n",
      "65/65 [==============================] - 120s 2s/step - loss: 0.3121 - val_loss: 0.3097\n",
      "Epoch 23/25\n",
      "65/65 [==============================] - 120s 2s/step - loss: 0.3064 - val_loss: 0.3044\n",
      "Epoch 24/25\n",
      "65/65 [==============================] - 116s 2s/step - loss: 0.3014 - val_loss: 0.2997\n",
      "Epoch 25/25\n",
      "39/65 [=================>............] - ETA: 37s - loss: 0.3021\n",
      "Epoch 00025: saving model to training/cp-0025.ckpt\n",
      "65/65 [==============================] - 112s 2s/step - loss: 0.2970 - val_loss: 0.2955\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:5'):\n",
    "    \n",
    "    model.fit(train_dataset,\n",
    "               epochs = 25,\n",
    "               validation_data = val_dataset,\n",
    "               callbacks = [cp_callback],),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1505906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
