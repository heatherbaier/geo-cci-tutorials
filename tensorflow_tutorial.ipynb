{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370542bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a059f3e9",
   "metadata": {},
   "source": [
    "First we need to set up some basic variables such as our batch size, country and data directories/paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671a5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRY = \"mex\"\n",
    "CSV_PATH = \"../../CCI/hmbaier/cci_final.csv\"\n",
    "IMAGERY_DIR = \"../../CCI/hmbaier/\"\n",
    "BATCH_SIZE = 64\n",
    "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f295009d",
   "metadata": {},
   "source": [
    "Next, we create a variables called files that contains the name of every image in our base folder, then we subset it to just the iamges for our selected country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2926122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../CCI/hmbaier/01DTV0015X_mex_2016-08-18_2017-05-17.png',\n",
       " '../../CCI/hmbaier/01DTV0005Q_mex_2016-08-18_2017-05-17.png',\n",
       " '../../CCI/hmbaier/01DTV0010B_mex_2016-08-18_2017-05-17.png',\n",
       " '../../CCI/hmbaier/01DTV0013Z_mex_2016-08-18_2017-05-17.png',\n",
       " '../../CCI/hmbaier/01DTV0002T_mex_2016-08-18_2017-05-17.png']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(IMAGERY_DIR)\n",
    "files = [IMAGERY_DIR + i for i in files if COUNTRY in i]\n",
    "\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec55e8",
   "metadata": {},
   "source": [
    "We will use a type of Python object called a Generator for our datalaoder. You can read more about them here: https://realpython.com/introduction-to-python-generators/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a7cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(files, split):\n",
    "\n",
    "    \"\"\" Split data into training and validation sets \"\"\"\n",
    "\n",
    "    train_num = int(len(files) * split)\n",
    "\n",
    "    train = random.sample(files, train_num)\n",
    "    val = [i for i in files if i not in train]\n",
    "\n",
    "    return train, val\n",
    "\n",
    "\n",
    "def get_train():\n",
    "\n",
    "    \"\"\" Training data generator \"\"\"\n",
    "\n",
    "    for file in train_files:\n",
    "        \n",
    "        # Grab the school_id from the image name\n",
    "        school_id = file.split(\"/\")[4].split(\"_\")[0]\n",
    "        \n",
    "        # Grab the test score for the current school from our scores dataframe\n",
    "        score = df[df[\"school_id\"] == school_id][\"y\"]\n",
    "        \n",
    "        if len(score) == 0:\n",
    "            score = 0\n",
    "        else:\n",
    "            score = score.squeeze()        \n",
    "        \n",
    "        # Read in our image and normalize it by divding it by the maximum value (this normalization is super important!)\n",
    "        im = cv2.imread(file)\n",
    "        im = im / np.max(im)\n",
    "                \n",
    "        # Create a tuple with (image array, test score) and return it\n",
    "        ret = ( np.array(im), np.reshape(np.array(score), (-1, 1)) )\n",
    "        \n",
    "        yield ret\n",
    "\n",
    "\n",
    "def get_val():\n",
    "\n",
    "    \"\"\" Validation data generator \"\"\"\n",
    "\n",
    "    for file in val_files:\n",
    "        school_id = file.split(\"/\")[4].split(\"_\")[0]\n",
    "        score = df[df[\"school_id\"] == school_id][\"y\"]\n",
    "        \n",
    "        if len(score) == 0:\n",
    "            score = 0\n",
    "        else:\n",
    "            score = score.squeeze()        \n",
    "        \n",
    "        im = cv2.imread(file)\n",
    "        im = im / np.max(im)\n",
    "                \n",
    "        ret = ( np.array(im), np.reshape(np.array(score), (-1, 1)) )       \n",
    "        \n",
    "        yield ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347c872",
   "metadata": {},
   "source": [
    "Read in our test scores dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b783961c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>school_id</th>\n",
       "      <th>test_score</th>\n",
       "      <th>scaled_score</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phl</td>\n",
       "      <td>107022</td>\n",
       "      <td>105.30</td>\n",
       "      <td>35.583573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phl</td>\n",
       "      <td>107023</td>\n",
       "      <td>137.05</td>\n",
       "      <td>58.458213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phl</td>\n",
       "      <td>107024</td>\n",
       "      <td>142.39</td>\n",
       "      <td>62.305476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phl</td>\n",
       "      <td>107025</td>\n",
       "      <td>166.03</td>\n",
       "      <td>79.337176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phl</td>\n",
       "      <td>107026</td>\n",
       "      <td>152.81</td>\n",
       "      <td>69.812680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country school_id  test_score  scaled_score  y\n",
       "0     phl    107022      105.30     35.583573  0\n",
       "1     phl    107023      137.05     58.458213  1\n",
       "2     phl    107024      142.39     62.305476  1\n",
       "3     phl    107025      166.03     79.337176  1\n",
       "4     phl    107026      152.81     69.812680  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e8d2d",
   "metadata": {},
   "source": [
    "Create a TensorFlow dataloader using the ```tf.data.Dataset.from_generator``` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce940813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files for mex: 10173\n",
      "Number of training files:  7629\n",
      "Number of validation files:  2544\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of image files for {COUNTRY}: {str(len(files))}\")\n",
    "\n",
    "train_files, val_files = train_test_split(files, .75)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(generator = get_train, output_types = (tf.float32, tf.float32)).batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_generator(generator = get_val, output_types = (tf.float32, tf.float32)).batch(BATCH_SIZE)\n",
    "\n",
    "print(\"Number of training files: \", len(train_files))\n",
    "print(\"Number of validation files: \", len(val_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475817f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top = False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape = (256, 256, 3),\n",
    "    pooling = 'avg',\n",
    "    classes = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284abd1",
   "metadata": {},
   "source": [
    "Create an compile our model using our selected parameters and metrics. In this case, I am using the BinaryCrossentropy Loss and a learning rate of 0.0001 along with the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479a7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f9ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq = 5 * BATCH_SIZE)\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129555cf",
   "metadata": {},
   "source": [
    "And finally, train your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73307db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    120/Unknown - 126s 1s/step - loss: 1.0773"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:4'):\n",
    "    \n",
    "    model.fit(train_dataset,\n",
    "               epochs = 1,\n",
    "               validation_data = val_dataset,\n",
    "               callbacks = [cp_callback],),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc26b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('model_v2/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551b0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
