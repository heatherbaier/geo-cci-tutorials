{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02929e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15520ad",
   "metadata": {},
   "source": [
    "First we need to set up some basic variables such as our batch size, country and data directories/paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8512d2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../CCI/hmbaier/107024_phl_2018-01-01_2018-03-31.png',\n",
       " '../../CCI/hmbaier/107025_phl_2018-01-01_2018-03-31.png',\n",
       " '../../CCI/hmbaier/107026_phl_2018-01-01_2018-03-31.png',\n",
       " '../../CCI/hmbaier/107027_phl_2013-09-01_2014-06-30.png',\n",
       " '../../CCI/hmbaier/107030_phl_2013-09-01_2014-06-30.png']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTRY = \"phl\"\n",
    "CSV_PATH = \"../../CCI/hmbaier/cci_example.csv\"\n",
    "IMAGERY_DIR = \"../../CCI/hmbaier/\"\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f455d30d",
   "metadata": {},
   "source": [
    "Next, we create a variables called files that contains the name of every image in our base folder, then we subset it to just the iamges for our selected country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(IMAGERY_DIR)\n",
    "files = [IMAGERY_DIR + i for i in files if COUNTRY in i]\n",
    "\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9caa7",
   "metadata": {},
   "source": [
    "We will use a type of Python object called a Generator for our datalaoder. You can read more about them here: https://realpython.com/introduction-to-python-generators/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1969aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(files, split):\n",
    "\n",
    "    \"\"\" Split data into training and validation sets \"\"\"\n",
    "\n",
    "    train_num = int(len(files) * split)\n",
    "\n",
    "    train = random.sample(files, train_num)\n",
    "    val = [i for i in files if i not in train]\n",
    "\n",
    "    return train, val\n",
    "\n",
    "\n",
    "def get_train():\n",
    "\n",
    "    \"\"\" Training data generator \"\"\"\n",
    "\n",
    "    for file in train_files:\n",
    "        \n",
    "        # Grab the school_id from the image name\n",
    "        school_id = file.split(\"/\")[4].split(\"_\")[0]\n",
    "        \n",
    "        # Grab the test score for the current school from our scores dataframe\n",
    "        score = df[df[\"school_id\"] == school_id][\"y\"].squeeze()\n",
    "        \n",
    "        # Read in our image and normalize it by divding it by the maximum value (this normalization is super important!)\n",
    "        im = cv2.imread(file)\n",
    "        im = im / np.max(im)\n",
    "\n",
    "        # Create a tuple with (image array, test score) and return it\n",
    "        ret = ( np.array(im), np.reshape(np.array(score), (-1, 1)) )\n",
    "        \n",
    "        yield ret\n",
    "\n",
    "\n",
    "def get_val():\n",
    "\n",
    "    \"\"\" Validation data generator \"\"\"\n",
    "\n",
    "    for file in val_files:\n",
    "        school_id = file.split(\"/\")[4].split(\"_\")[0]\n",
    "        score = df[df[\"school_id\"] == school_id][\"y\"].squeeze()\n",
    "        im = cv2.imread(file)\n",
    "        im = im / np.max(im)\n",
    "        ret = ( np.array(im), np.reshape(np.array(score), (-1, 1)) )\n",
    "        yield ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2f978",
   "metadata": {},
   "source": [
    "Read in our test scores dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2984aa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>school_id</th>\n",
       "      <th>test_score</th>\n",
       "      <th>scaled_score</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phl</td>\n",
       "      <td>107022</td>\n",
       "      <td>105.30</td>\n",
       "      <td>35.583573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phl</td>\n",
       "      <td>107023</td>\n",
       "      <td>137.05</td>\n",
       "      <td>58.458213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phl</td>\n",
       "      <td>107024</td>\n",
       "      <td>142.39</td>\n",
       "      <td>62.305476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phl</td>\n",
       "      <td>107025</td>\n",
       "      <td>166.03</td>\n",
       "      <td>79.337176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phl</td>\n",
       "      <td>107026</td>\n",
       "      <td>152.81</td>\n",
       "      <td>69.812680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country school_id  test_score  scaled_score  y\n",
       "0     phl    107022      105.30     35.583573  0\n",
       "1     phl    107023      137.05     58.458213  1\n",
       "2     phl    107024      142.39     62.305476  1\n",
       "3     phl    107025      166.03     79.337176  1\n",
       "4     phl    107026      152.81     69.812680  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161298f",
   "metadata": {},
   "source": [
    "Create a TensorFlow dataloader using the ```tf.data.Dataset.from_generator``` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e391c933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nCDF files:  5502\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of image files for {COUNTRY}: {str(len(files))}\")\n",
    "\n",
    "train_files, val_files = train_test_split(files, .75)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(generator = get_train, output_types = (tf.float32, tf.float32)).batch(BATCH_SIZE)\n",
    "val_dataset = tf.data.Dataset.from_generator(generator = get_val, output_types = (tf.float32, tf.float32)).batch(BATCH_SIZE)\n",
    "\n",
    "print(\"Number of training files: \", len(train_files))\n",
    "print(\"Number of validation files: \", len(val_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e34de62",
   "metadata": {},
   "source": [
    "Create an compile our model using our selected parameters and metrics. In this case, I am using the MeanAbsoluteError Loss and a learning rate of 0.0001 along with the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c35b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet.resnet56(img_input = tf.keras.layers.Input((256, 256, 3)), classes = 1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "    loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "    metrics = [tf.keras.losses.MeanAbsoluteError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33033a4f",
   "metadata": {},
   "source": [
    "And finally, train your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f4ae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "65/65 [==============================] - 170s 3s/step - loss: 1.0582 - mean_absolute_error: 0.2535 - val_loss: 1.0024 - val_mean_absolute_error: 0.2599\n",
      "Epoch 2/25\n",
      "65/65 [==============================] - 115s 2s/step - loss: 0.9529 - mean_absolute_error: 0.2535 - val_loss: 0.9049 - val_mean_absolute_error: 0.2599\n",
      "Epoch 3/25\n",
      "65/65 [==============================] - 112s 2s/step - loss: 0.8623 - mean_absolute_error: 0.2535 - val_loss: 0.8211 - val_mean_absolute_error: 0.2599\n",
      "Epoch 4/25\n",
      "65/65 [==============================] - 117s 2s/step - loss: 0.7844 - mean_absolute_error: 0.2535 - val_loss: 0.7489 - val_mean_absolute_error: 0.2599\n",
      "Epoch 5/25\n",
      "65/65 [==============================] - 117s 2s/step - loss: 0.7172 - mean_absolute_error: 0.2535 - val_loss: 0.6866 - val_mean_absolute_error: 0.2599\n",
      "Epoch 6/25\n",
      "65/65 [==============================] - 116s 2s/step - loss: 0.6591 - mean_absolute_error: 0.2535 - val_loss: 0.6328 - val_mean_absolute_error: 0.2599\n",
      "Epoch 7/25\n",
      "65/65 [==============================] - 116s 2s/step - loss: 0.6088 - mean_absolute_error: 0.2535 - val_loss: 0.5861 - val_mean_absolute_error: 0.2599\n",
      "Epoch 8/25\n",
      "65/65 [==============================] - 115s 2s/step - loss: 0.5652 - mean_absolute_error: 0.2535 - val_loss: 0.5456 - val_mean_absolute_error: 0.2599\n",
      "Epoch 9/25\n",
      "65/65 [==============================] - 115s 2s/step - loss: 0.5274 - mean_absolute_error: 0.2535 - val_loss: 0.5104 - val_mean_absolute_error: 0.2599\n",
      "Epoch 10/25\n",
      "65/65 [==============================] - 117s 2s/step - loss: 0.4945 - mean_absolute_error: 0.2535 - val_loss: 0.4798 - val_mean_absolute_error: 0.2599\n",
      "Epoch 11/25\n",
      "65/65 [==============================] - 115s 2s/step - loss: 0.4659 - mean_absolute_error: 0.2535 - val_loss: 0.4532 - val_mean_absolute_error: 0.2599\n",
      "Epoch 12/25\n",
      "65/65 [==============================] - 126s 2s/step - loss: 0.4410 - mean_absolute_error: 0.2535 - val_loss: 0.4301 - val_mean_absolute_error: 0.2599\n",
      "Epoch 13/25\n",
      "65/65 [==============================] - 120s 2s/step - loss: 0.4194 - mean_absolute_error: 0.2535 - val_loss: 0.4099 - val_mean_absolute_error: 0.2599\n",
      "Epoch 14/25\n",
      "65/65 [==============================] - 118s 2s/step - loss: 0.4005 - mean_absolute_error: 0.2535 - val_loss: 0.3923 - val_mean_absolute_error: 0.2599\n",
      "Epoch 15/25\n",
      "65/65 [==============================] - 115s 2s/step - loss: 0.3840 - mean_absolute_error: 0.2535 - val_loss: 0.3769 - val_mean_absolute_error: 0.2599\n",
      "Epoch 16/25\n",
      "65/65 [==============================] - 118s 2s/step - loss: 0.3696 - mean_absolute_error: 0.2535 - val_loss: 0.3635 - val_mean_absolute_error: 0.2599\n",
      "Epoch 17/25\n",
      "65/65 [==============================] - 114s 2s/step - loss: 0.3571 - mean_absolute_error: 0.2535 - val_loss: 0.3518 - val_mean_absolute_error: 0.2599\n",
      "Epoch 18/25\n",
      "65/65 [==============================] - 118s 2s/step - loss: 0.3461 - mean_absolute_error: 0.2535 - val_loss: 0.3416 - val_mean_absolute_error: 0.2599\n",
      "Epoch 19/25\n",
      "65/65 [==============================] - 122s 2s/step - loss: 0.3365 - mean_absolute_error: 0.2535 - val_loss: 0.3326 - val_mean_absolute_error: 0.2599\n",
      "Epoch 20/25\n",
      "65/65 [==============================] - 117s 2s/step - loss: 0.3281 - mean_absolute_error: 0.2535 - val_loss: 0.3247 - val_mean_absolute_error: 0.2599\n",
      "Epoch 21/25\n",
      "65/65 [==============================] - 115s 2s/step - loss: 0.3207 - mean_absolute_error: 0.2535 - val_loss: 0.3178 - val_mean_absolute_error: 0.2599\n",
      "Epoch 22/25\n",
      "65/65 [==============================] - 117s 2s/step - loss: 0.3142 - mean_absolute_error: 0.2535 - val_loss: 0.3118 - val_mean_absolute_error: 0.2599\n",
      "Epoch 23/25\n",
      "65/65 [==============================] - 109s 2s/step - loss: 0.3085 - mean_absolute_error: 0.2535 - val_loss: 0.3064 - val_mean_absolute_error: 0.2599\n",
      "Epoch 24/25\n",
      "65/65 [==============================] - 114s 2s/step - loss: 0.3035 - mean_absolute_error: 0.2535 - val_loss: 0.3017 - val_mean_absolute_error: 0.2599\n",
      "Epoch 25/25\n",
      "51/65 [======================>.......] - ETA: 19s - loss: 0.3023 - mean_absolute_error: 0.2574"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:5'):\n",
    "    \n",
    "    model.fit(train_dataset,\n",
    "               epochs = 25,\n",
    "               validation_data = val_dataset),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc44a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
