{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209bd205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12f4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ef2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46524404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    \n",
    "    def __init__(self, country, imagery_direc, scores_df, split, batch_size, tfs = None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            country: one of ['mex', 'slv', 'peru', 'phl']\n",
    "            imagery_direc: path to folder containing school imagery\n",
    "            scores_df: path to CSV file with school IDs and test scroes\n",
    "            split: train/test split, should be between .01 and 1, recommended is between .65 and .8\n",
    "            batch_size: number of images in a batch\n",
    "        \"\"\"\n",
    "        self.country = country\n",
    "        self.imagery_direc = imagery_direc\n",
    "        self.imagery = os.listdir(self.imagery_direc)\n",
    "        self.imagery = [i for i in self.imagery if self.country in i]\n",
    "        self.scores_df = pd.read_csv(scores_df)\n",
    "        self.scores_df = self.scores_df[self.scores_df['country'] == self.country]\n",
    "        self.split = split\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        if tfs is None:\n",
    "            self.tfs = transforms.ToTensor()\n",
    "        else:\n",
    "            self.tfs = tfs\n",
    "        \n",
    "        # Load the data into a list with the format [(school_image, school_test_score), ...]\n",
    "        self.data = self.load_data()\n",
    "        \n",
    "        # Split the data into training and validation sets\n",
    "        self.train, self.val = self.test_train_split()\n",
    "        \n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load the imagery into a list in the format: [(imager_tensor, test_score), ...]\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for col, row in self.scores_df.iterrows():\n",
    "            school_id = str(row.school_id)\n",
    "            test_score = row.y\n",
    "            impath = [i for i in self.imagery if school_id in i]\n",
    "            if len(impath) > 0:\n",
    "                image = np.array(Image.open(self.imagery_direc + impath[0]))\n",
    "                image = self.tfs(image)\n",
    "                data.append((image, test_score))\n",
    "        return data\n",
    "                \n",
    "        \n",
    "    def test_train_split(self):\n",
    "        \"\"\"\n",
    "        Split the data into 4 parts:\n",
    "            x_train: imagery we use to train the model\n",
    "            y_train: test_scores matched to the iamgery in x_train\n",
    "            x_val: imagery used to test the model\n",
    "            y_val: test_scores matched to the iamgery in x_val\n",
    "        \"\"\"\n",
    "        train_num = int(len(self.data) * self.split)\n",
    "        val_num = int(len(self.data) - train_num)\n",
    "\n",
    "        all_indices = list(range(0, len(self.data)))\n",
    "        train_indices = random.sample(range(len(self.data)), train_num)\n",
    "        val_indices = list(np.setdiff1d(all_indices, train_indices))\n",
    "\n",
    "        x_train, x_val = [self.data[i][0] for i in train_indices], [self.data[i][0] for i in val_indices]\n",
    "        y_train, y_val = [self.data[i][1] for i in train_indices], [self.data[i][1] for i in val_indices]\n",
    "        \n",
    "        train = [(k,v) for k,v in zip(x_train, y_train)]\n",
    "        val = [(k,v) for k,v in zip(x_val, y_val)]\n",
    "\n",
    "        # Load the data into PyTorch's Dataloader format\n",
    "        train = torch.utils.data.DataLoader(train, batch_size = self.batch_size, shuffle = True, drop_last = True)\n",
    "        val = torch.utils.data.DataLoader(val, batch_size = self.batch_size, shuffle = True, drop_last = True)\n",
    "\n",
    "        return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20fd3548",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRY = \"bra\"\n",
    "BATCH_SIZE = 4\n",
    "SPLIT = .75\n",
    "IMAGERY_DIREC = \"../../CCI/hmbaier/\"\n",
    "SCORES_DF = \"./cci_final.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a38ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataloader(country = COUNTRY, \n",
    "                  imagery_direc = IMAGERY_DIREC, \n",
    "                  scores_df = SCORES_DF,\n",
    "                  split = SPLIT,\n",
    "                  batch_size = BATCH_SIZE,\n",
    "                  tfs = tfs)\n",
    "all_data = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4fc9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the to keep track of our training stastics (i.e. running training loss, running validation loss, etc...)\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n = 1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = round(self.sum / self.count, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2282ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a basic off the shelf \n",
    "model = models.resnet18(pretrained = True)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint = torch.load(\"./trained_phl_model.torch\")[\"model_state_dict\"]\n",
    "\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1224ab7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "sm = torch.nn.Softmax()\n",
    "trues, preds = [], []\n",
    "\n",
    "for (inputs, targets) in all_data:\n",
    "        \n",
    "    inputs, targets = inputs.unsqueeze(0).to(device), torch.tensor(targets)\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    _, pred = torch.max(sm(outputs), 1)\n",
    "        \n",
    "    trues.append(targets.item())\n",
    "    preds.append(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb0f9703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 2140],\n",
       "       [   0, 4601]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "cm = confusion_matrix(trues, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0c80d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6825396825396826"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(trues, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
